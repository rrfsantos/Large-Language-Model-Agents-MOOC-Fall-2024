{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rrfsantos/Large-Language-Model-Agents-MOOC-Fall-2024/blob/main/AI%20Agentic%20Design%20Patterns%20with%20AutoGen/L2_Sequential_Chats_and_Customer_Onboarding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8140b161",
      "metadata": {
        "id": "8140b161"
      },
      "source": [
        "# Lesson 2: Sequential Chats and Customer Onboarding"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9d4d307",
      "metadata": {
        "id": "e9d4d307"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecDJ646B0U4C",
        "outputId": "cd65902f-aac7-4bd6-ed4a-127f492ca88d"
      },
      "id": "ecDJ646B0U4C",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r /content/drive/MyDrive/AutoGen/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5ORLFil0XvF",
        "outputId": "a99a0932-9167-4665-c656-800178b90771"
      },
      "id": "j5ORLFil0XvF",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyautogen==0.2.25 (from -r /content/drive/MyDrive/AutoGen/requirements.txt (line 6))\n",
            "  Downloading pyautogen-0.2.25-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting chess==1.10.0 (from -r /content/drive/MyDrive/AutoGen/requirements.txt (line 7))\n",
            "  Downloading chess-1.10.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/AutoGen/requirements.txt (line 8)) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/AutoGen/requirements.txt (line 9)) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/AutoGen/requirements.txt (line 10)) (2.2.2)\n",
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/AutoGen/requirements.txt (line 11)) (0.2.46)\n",
            "Collecting diskcache (from pyautogen==0.2.25->-r /content/drive/MyDrive/AutoGen/requirements.txt (line 6))\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting docker (from pyautogen==0.2.25->-r /content/drive/MyDrive/AutoGen/requirements.txt (line 6))\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting flaml (from pyautogen==0.2.25->-r /content/drive/MyDrive/AutoGen/requirements.txt (line 6))\n",
            "  Downloading FLAML-2.3.1-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting openai>=1.3 (from pyautogen==0.2.25->-r /content/drive/MyDrive/AutoGen/requirements.txt (line 6))\n",
            "  Downloading openai-1.52.2-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: pydantic!=2.6.0,<3,>=1.10 in /usr/local/lib/python3.10/dist-packages (from pyautogen==0.2.25->-r /content/drive/MyDrive/AutoGen/requirements.txt (line 6)) (2.9.2)\n",
            "Collecting python-dotenv (from pyautogen==0.2.25->-r /content/drive/MyDrive/AutoGen/requirements.txt (line 6))\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from pyautogen==0.2.25->-r /content/drive/MyDrive/AutoGen/requirements.txt (line 6)) (2.5.0)\n",
            "Collecting tiktoken (from pyautogen==0.2.25->-r /content/drive/MyDrive/AutoGen/requirements.txt (line 6))\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/drive/MyDrive/AutoGen/requirements.txt (line 8)) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/drive/MyDrive/AutoGen/requirements.txt (line 8)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/drive/MyDrive/AutoGen/requirements.txt (line 8)) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/drive/MyDrive/AutoGen/requirements.txt (line 8)) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/drive/MyDrive/AutoGen/requirements.txt (line 8)) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/drive/MyDrive/AutoGen/requirements.txt (line 8)) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/drive/MyDrive/AutoGen/requirements.txt (line 8)) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/drive/MyDrive/AutoGen/requirements.txt (line 8)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r /content/drive/MyDrive/AutoGen/requirements.txt (line 10)) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->-r /content/drive/MyDrive/AutoGen/requirements.txt (line 10)) (2024.2)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.10/dist-packages (from yfinance->-r /content/drive/MyDrive/AutoGen/requirements.txt (line 11)) (2.32.3)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from yfinance->-r /content/drive/MyDrive/AutoGen/requirements.txt (line 11)) (0.0.11)\n",
            "Requirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from yfinance->-r /content/drive/MyDrive/AutoGen/requirements.txt (line 11)) (4.9.4)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from yfinance->-r /content/drive/MyDrive/AutoGen/requirements.txt (line 11)) (4.3.6)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.10/dist-packages (from yfinance->-r /content/drive/MyDrive/AutoGen/requirements.txt (line 11)) (2.4.6)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.10/dist-packages (from yfinance->-r /content/drive/MyDrive/AutoGen/requirements.txt (line 11)) (3.17.7)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.10/dist-packages (from yfinance->-r /content/drive/MyDrive/AutoGen/requirements.txt (line 11)) (4.12.3)\n",
            "Requirement already satisfied: html5lib>=1.1 in /usr/local/lib/python3.10/dist-packages (from yfinance->-r /content/drive/MyDrive/AutoGen/requirements.txt (line 11)) (1.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.11.1->yfinance->-r /content/drive/MyDrive/AutoGen/requirements.txt (line 11)) (2.6)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance->-r /content/drive/MyDrive/AutoGen/requirements.txt (line 11)) (1.16.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance->-r /content/drive/MyDrive/AutoGen/requirements.txt (line 11)) (0.5.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->pyautogen==0.2.25->-r /content/drive/MyDrive/AutoGen/requirements.txt (line 6)) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.3->pyautogen==0.2.25->-r /content/drive/MyDrive/AutoGen/requirements.txt (line 6)) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai>=1.3->pyautogen==0.2.25->-r /content/drive/MyDrive/AutoGen/requirements.txt (line 6))\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai>=1.3->pyautogen==0.2.25->-r /content/drive/MyDrive/AutoGen/requirements.txt (line 6))\n",
            "  Downloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->pyautogen==0.2.25->-r /content/drive/MyDrive/AutoGen/requirements.txt (line 6)) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->pyautogen==0.2.25->-r /content/drive/MyDrive/AutoGen/requirements.txt (line 6)) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->pyautogen==0.2.25->-r /content/drive/MyDrive/AutoGen/requirements.txt (line 6)) (4.12.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=2.6.0,<3,>=1.10->pyautogen==0.2.25->-r /content/drive/MyDrive/AutoGen/requirements.txt (line 6)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=2.6.0,<3,>=1.10->pyautogen==0.2.25->-r /content/drive/MyDrive/AutoGen/requirements.txt (line 6)) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance->-r /content/drive/MyDrive/AutoGen/requirements.txt (line 11)) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance->-r /content/drive/MyDrive/AutoGen/requirements.txt (line 11)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance->-r /content/drive/MyDrive/AutoGen/requirements.txt (line 11)) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance->-r /content/drive/MyDrive/AutoGen/requirements.txt (line 11)) (2024.8.30)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->pyautogen==0.2.25->-r /content/drive/MyDrive/AutoGen/requirements.txt (line 6)) (2024.9.11)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.3->pyautogen==0.2.25->-r /content/drive/MyDrive/AutoGen/requirements.txt (line 6)) (1.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai>=1.3->pyautogen==0.2.25->-r /content/drive/MyDrive/AutoGen/requirements.txt (line 6))\n",
            "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.3->pyautogen==0.2.25->-r /content/drive/MyDrive/AutoGen/requirements.txt (line 6))\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Downloading pyautogen-0.2.25-py3-none-any.whl (257 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m257.1/257.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chess-1.10.0-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.4/154.4 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.52.2-py3-none-any.whl (386 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.9/386.9 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading FLAML-2.3.1-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.3/313.3 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.2/325.2 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-dotenv, jiter, h11, flaml, diskcache, chess, tiktoken, httpcore, docker, httpx, openai, pyautogen\n",
            "Successfully installed chess-1.10.0 diskcache-5.6.3 docker-7.1.0 flaml-2.3.1 h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 jiter-0.6.1 openai-1.52.2 pyautogen-0.2.25 python-dotenv-1.0.1 tiktoken-0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "20ce6700-8a33-424f-aefe-8852fd1e6d07",
      "metadata": {
        "height": 30,
        "id": "20ce6700-8a33-424f-aefe-8852fd1e6d07"
      },
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "import warnings\n",
        "import os\n",
        "from autogen import ConversableAgent, initiate_chats\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.simplefilter(action='ignore', category=UserWarning)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load environment variables from .env file\n",
        "load_dotenv(\"/content/drive/MyDrive/AutoGen/env\")\n",
        "llm_config = {\"config_list\": [{\"model\": \"gpt-3.5-turbo\", \"api_key\" : os.getenv(\"OPENAI_API_KEY\")}]}"
      ],
      "metadata": {
        "id": "c6YJLWGz0sbW"
      },
      "id": "c6YJLWGz0sbW",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "76f979f9",
      "metadata": {
        "id": "76f979f9"
      },
      "source": [
        "## Creating the needed agents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "a527bb1e-dd4e-47b0-a1b7-a9cbcd87cbdb",
      "metadata": {
        "height": 200,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a527bb1e-dd4e-47b0-a1b7-a9cbcd87cbdb",
        "outputId": "32247be2-e380-4a33-a9ff-0fc9c6625e37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[autogen.oai.client: 10-28 15:52:02] {129} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        }
      ],
      "source": [
        "onboarding_personal_information_agent = ConversableAgent(\n",
        "    name=\"Onboarding Personal Information Agent\",\n",
        "    system_message='''You are a helpful customer onboarding agent,\n",
        "    you are here to help new customers get started with our product.\n",
        "    Your job is to gather customer's name and location.\n",
        "    Do not ask for other information. Return 'TERMINATE'\n",
        "    when you have gathered all the information.''',\n",
        "    llm_config=llm_config,\n",
        "    code_execution_config=False,\n",
        "    human_input_mode=\"NEVER\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "51bc9a24-a680-444d-943b-b740bce0189d",
      "metadata": {
        "height": 215,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51bc9a24-a680-444d-943b-b740bce0189d",
        "outputId": "23be5716-b291-4daf-f054-8bc7eda8c04a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[autogen.oai.client: 10-28 15:52:09] {129} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        }
      ],
      "source": [
        "onboarding_topic_preference_agent = ConversableAgent(\n",
        "    name=\"Onboarding Topic preference Agent\",\n",
        "    system_message='''You are a helpful customer onboarding agent,\n",
        "    you are here to help new customers get started with our product.\n",
        "    Your job is to gather customer's preferences on news topics.\n",
        "    Do not ask for other information.\n",
        "    Return 'TERMINATE' when you have gathered all the information.''',\n",
        "    llm_config=llm_config,\n",
        "    code_execution_config=False,\n",
        "    human_input_mode=\"NEVER\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "6755a7fc-cb17-4d62-a03f-48e260f39010",
      "metadata": {
        "height": 249,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6755a7fc-cb17-4d62-a03f-48e260f39010",
        "outputId": "f9aacd9b-4943-4474-9dec-f9c03fdb1621"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[autogen.oai.client: 10-28 15:52:49] {129} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        }
      ],
      "source": [
        "customer_engagement_agent = ConversableAgent(\n",
        "    name=\"Customer Engagement Agent\",\n",
        "    system_message='''You are a helpful customer service agent\n",
        "    here to provide fun for the customer based on the user's\n",
        "    personal information and topic preferences.\n",
        "    This could include fun facts, jokes, or interesting stories.\n",
        "    Make sure to make it engaging and fun!\n",
        "    Return 'TERMINATE' when you are done.''',\n",
        "    llm_config=llm_config,\n",
        "    code_execution_config=False,\n",
        "    human_input_mode=\"NEVER\",\n",
        "    is_termination_msg=lambda msg: \"terminate\" in msg.get(\"content\").lower(),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "64267c0b-f7f2-46e6-ab44-6f7b5fbd9db7",
      "metadata": {
        "height": 147,
        "id": "64267c0b-f7f2-46e6-ab44-6f7b5fbd9db7"
      },
      "outputs": [],
      "source": [
        "customer_proxy_agent = ConversableAgent(\n",
        "    name=\"customer_proxy_agent\",\n",
        "    llm_config=False,\n",
        "    code_execution_config=False,\n",
        "    human_input_mode=\"ALWAYS\",\n",
        "    is_termination_msg=lambda msg: \"terminate\" in msg.get(\"content\").lower(),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f240408",
      "metadata": {
        "id": "4f240408"
      },
      "source": [
        "## Creating tasks\n",
        "\n",
        "Now, you can craft a series of tasks to facilitate the onboarding process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "2b15af1d-7042-4569-a936-7966be203f05",
      "metadata": {
        "height": 606,
        "id": "2b15af1d-7042-4569-a936-7966be203f05"
      },
      "outputs": [],
      "source": [
        "chats = [\n",
        "    {\n",
        "        \"sender\": onboarding_personal_information_agent,\n",
        "        \"recipient\": customer_proxy_agent,\n",
        "        \"message\":\n",
        "            \"Hello, I'm here to help you get started with our product.\"\n",
        "            \"Could you tell me your name and location?\",\n",
        "        \"summary_method\": \"reflection_with_llm\",\n",
        "        \"summary_args\": {\n",
        "            \"summary_prompt\" : \"Return the customer information \"\n",
        "                             \"into as JSON object only: \"\n",
        "                             \"{'name': '', 'location': ''}\",\n",
        "        },\n",
        "        \"max_turns\": 2,\n",
        "        \"clear_history\" : True\n",
        "    },\n",
        "    {\n",
        "        \"sender\": onboarding_topic_preference_agent,\n",
        "        \"recipient\": customer_proxy_agent,\n",
        "        \"message\":\n",
        "                \"Great! Could you tell me what topics you are \"\n",
        "                \"interested in reading about?\",\n",
        "        \"summary_method\": \"reflection_with_llm\",\n",
        "        \"max_turns\": 1,\n",
        "        \"clear_history\" : False\n",
        "    },\n",
        "    {\n",
        "        \"sender\": customer_proxy_agent,\n",
        "        \"recipient\": customer_engagement_agent,\n",
        "        \"message\": \"Let's find something fun to read.\",\n",
        "        \"max_turns\": 1,\n",
        "        \"summary_method\": \"reflection_with_llm\",\n",
        "    },\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "862a066b",
      "metadata": {
        "id": "862a066b"
      },
      "source": [
        "## Start the onboarding process"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0fa8f99",
      "metadata": {
        "id": "e0fa8f99"
      },
      "source": [
        "**Note**: You might get a slightly different response than what's shown in the video. Feel free to try different inputs, such as name, location, and preferences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "9d6d1d4a-0b50-41a5-a1f0-3ff208398bc6",
      "metadata": {
        "height": 64,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9d6d1d4a-0b50-41a5-a1f0-3ff208398bc6",
        "outputId": "37a6dd06-b6fc-441c-b780-3df818633808"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "********************************************************************************\n",
            "Starting a new chat....\n",
            "\n",
            "********************************************************************************\n",
            "Onboarding Personal Information Agent (to customer_proxy_agent):\n",
            "\n",
            "Hello, I'm here to help you get started with our product.Could you tell me your name and location?\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Provide feedback to Onboarding Personal Information Agent. Press enter to skip and use auto-reply, or type 'exit' to end the conversation: Reanata Rio de janeiro\n",
            "customer_proxy_agent (to Onboarding Personal Information Agent):\n",
            "\n",
            "Reanata Rio de janeiro\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Onboarding Personal Information Agent (to customer_proxy_agent):\n",
            "\n",
            "Great! Thank you for providing your name and location. Is there anything else I can assist you with today, or are you all set for now?\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Provide feedback to Onboarding Personal Information Agent. Press enter to skip and use auto-reply, or type 'exit' to end the conversation: \n",
            "\n",
            ">>>>>>>> NO HUMAN INPUT RECEIVED.\n",
            "\n",
            ">>>>>>>> USING AUTO REPLY...\n",
            "customer_proxy_agent (to Onboarding Personal Information Agent):\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "********************************************************************************\n",
            "Starting a new chat....\n",
            "\n",
            "********************************************************************************\n",
            "Onboarding Topic preference Agent (to customer_proxy_agent):\n",
            "\n",
            "Great! Could you tell me what topics you are interested in reading about?\n",
            "Context: \n",
            "{\n",
            "  \"name\": \"Reanata\",\n",
            "  \"location\": \"Rio de Janeiro\"\n",
            "}\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Provide feedback to Onboarding Topic preference Agent. Press enter to skip and use auto-reply, or type 'exit' to end the conversation: Carros\n",
            "customer_proxy_agent (to Onboarding Topic preference Agent):\n",
            "\n",
            "Carros\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "********************************************************************************\n",
            "Starting a new chat....\n",
            "\n",
            "********************************************************************************\n",
            "customer_proxy_agent (to Customer Engagement Agent):\n",
            "\n",
            "Let's find something fun to read.\n",
            "Context: \n",
            "{\n",
            "  \"name\": \"Reanata\",\n",
            "  \"location\": \"Rio de Janeiro\"\n",
            "}\n",
            "The person is from Rio de Janeiro and is interested in reading about cars.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Customer Engagement Agent (to customer_proxy_agent):\n",
            "\n",
            "Hey Renata! Did you know that Rio de Janeiro is home to one of the world's most famous car races - the Rio de Janeiro Grand Prix? This annual event attracts top drivers and car enthusiasts from around the globe to compete in the beautiful streets of Rio.\n",
            "\n",
            "If you're interested in cars, you might enjoy reading about the history of this exciting race and the fast cars that zoom through the city streets. It's a thrilling combination of speed, skill, and adrenaline!\n",
            "\n",
            "I hope this fun fact adds some excitement to your reading adventures! If you'd like more car-related recommendations or any other topic, feel free to let me know! 😊\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "chat_results = initiate_chats(chats)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f9e2713",
      "metadata": {
        "id": "4f9e2713"
      },
      "source": [
        "## Print out the summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "1e122f8a-1ceb-4635-9672-662114b0552a",
      "metadata": {
        "height": 64,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1e122f8a-1ceb-4635-9672-662114b0552a",
        "outputId": "e826d47d-3c61-4a3c-ad2a-6ed8d6356701"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"name\": \"Reanata\",\n",
            "  \"location\": \"Rio de Janeiro\"\n",
            "}\n",
            "\n",
            "\n",
            "The person is from Rio de Janeiro and is interested in reading about cars.\n",
            "\n",
            "\n",
            "Renata from Rio de Janeiro may enjoy reading about the Rio de Janeiro Grand Prix, a popular car race held in the city. It is an exciting event that attracts top drivers and car enthusiasts from around the world.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for chat_result in chat_results:\n",
        "    print(chat_result.summary)\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a674c4eb",
      "metadata": {
        "id": "a674c4eb"
      },
      "source": [
        "## Print out the cost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "8b82a10a-afe5-4ba3-97b4-41c8c14b739f",
      "metadata": {
        "height": 64,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8b82a10a-afe5-4ba3-97b4-41c8c14b739f",
        "outputId": "5c2a4711-fce9-4a9c-d03f-d525f802998c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'usage_including_cached_inference': {'total_cost': 0.000178, 'gpt-3.5-turbo-0125': {'cost': 0.000178, 'prompt_tokens': 206, 'completion_tokens': 50, 'total_tokens': 256}}, 'usage_excluding_cached_inference': {'total_cost': 0.000178, 'gpt-3.5-turbo-0125': {'cost': 0.000178, 'prompt_tokens': 206, 'completion_tokens': 50, 'total_tokens': 256}}}\n",
            "\n",
            "\n",
            "{'usage_including_cached_inference': {'total_cost': 5.8e-05, 'gpt-3.5-turbo-0125': {'cost': 5.8e-05, 'prompt_tokens': 71, 'completion_tokens': 15, 'total_tokens': 86}}, 'usage_excluding_cached_inference': {'total_cost': 5.8e-05, 'gpt-3.5-turbo-0125': {'cost': 5.8e-05, 'prompt_tokens': 71, 'completion_tokens': 15, 'total_tokens': 86}}}\n",
            "\n",
            "\n",
            "{'usage_including_cached_inference': {'total_cost': 0.00042350000000000005, 'gpt-3.5-turbo-0125': {'cost': 0.00042350000000000005, 'prompt_tokens': 328, 'completion_tokens': 173, 'total_tokens': 501}}, 'usage_excluding_cached_inference': {'total_cost': 0.00042350000000000005, 'gpt-3.5-turbo-0125': {'cost': 0.00042350000000000005, 'prompt_tokens': 328, 'completion_tokens': 173, 'total_tokens': 501}}}\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for chat_result in chat_results:\n",
        "    print(chat_result.cost)\n",
        "    print(\"\\n\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}