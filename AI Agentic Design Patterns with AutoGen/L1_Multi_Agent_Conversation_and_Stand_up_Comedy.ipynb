{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rrfsantos/Large-Language-Model-Agents-MOOC-Fall-2024/blob/main/AI%20Agentic%20Design%20Patterns%20with%20AutoGen/L1_Multi_Agent_Conversation_and_Stand_up_Comedy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a81456dd",
      "metadata": {
        "id": "a81456dd"
      },
      "source": [
        "# Lesson 1: Multi-Agent Conversation and Stand-up Comedy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4693467e",
      "metadata": {
        "id": "4693467e"
      },
      "source": [
        "Welcome to Lesson 1.\n",
        "\n",
        "To access the `requirements.txt` file and the`utils` modules, please go to the `File` menu and select`Open...`.\n",
        "\n",
        "I hope you enjoy this course!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "742cf649",
      "metadata": {
        "id": "742cf649"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aX3T60wxvXBC",
        "outputId": "958b394c-b1af-4fd7-9d41-422f63196a4d"
      },
      "id": "aX3T60wxvXBC",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r /content/drive/MyDrive/AutoGen/requirements.txt"
      ],
      "metadata": {
        "id": "aKn0h58RvYl8"
      },
      "id": "aKn0h58RvYl8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "import warnings\n",
        "import os\n",
        "from autogen import ConversableAgent\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)"
      ],
      "metadata": {
        "id": "b8J4B7ndwePT"
      },
      "id": "b8J4B7ndwePT",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load environment variables from .env file\n",
        "load_dotenv(\"/content/drive/MyDrive/AutoGen/env\")\n",
        "llm_config = {\"config_list\": [{\"model\": \"gpt-3.5-turbo\", \"api_key\" : os.getenv(\"OPENAI_API_KEY\")}]}"
      ],
      "metadata": {
        "id": "OKAg7P91xpmW"
      },
      "id": "OKAg7P91xpmW",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "116a1c4d",
      "metadata": {
        "id": "116a1c4d"
      },
      "source": [
        "## Define an AutoGen agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "6fb8c441-c58c-41a8-a54b-5c387afceac5",
      "metadata": {
        "height": 132,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fb8c441-c58c-41a8-a54b-5c387afceac5",
        "outputId": "4623b75b-068f-4bf3-dce5-89fc507b152c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[autogen.oai.client: 10-28 15:38:26] {129} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        }
      ],
      "source": [
        "agent = ConversableAgent(\n",
        "    name=\"chatbot\",\n",
        "    llm_config=llm_config,\n",
        "    human_input_mode=\"NEVER\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "47886b5f-fc7c-431a-8036-cff6e88f85c6",
      "metadata": {
        "height": 81,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47886b5f-fc7c-431a-8036-cff6e88f85c6",
        "outputId": "1ce06978-5556-4e3e-bd6b-baa3ff1bd334"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sure, here's one for you: Why don't scientists trust atoms? Because they make up everything!\n"
          ]
        }
      ],
      "source": [
        "reply = agent.generate_reply(\n",
        "    messages=[{\"content\": \"Tell me a joke.\", \"role\": \"user\"}]\n",
        ")\n",
        "print(reply)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "67f626e9-4cec-40c1-abde-2eff1252b848",
      "metadata": {
        "height": 81,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67f626e9-4cec-40c1-abde-2eff1252b848",
        "outputId": "5d310a2e-9646-4cec-f7a8-38435969c920"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Of course! Can you remind me which joke you'd like me to repeat for you?\n"
          ]
        }
      ],
      "source": [
        "reply = agent.generate_reply(\n",
        "    messages=[{\"content\": \"Repeat the joke.\", \"role\": \"user\"}]\n",
        ")\n",
        "print(reply)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c98a301",
      "metadata": {
        "id": "8c98a301"
      },
      "source": [
        "## Conversation\n",
        "\n",
        "Setting up a conversation between two agents, Cathy and Joe, where the memory of their interactions is retained."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "8f109dcb-824e-40d7-8e86-efee42b75f3c",
      "metadata": {
        "height": 285,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8f109dcb-824e-40d7-8e86-efee42b75f3c",
        "outputId": "f460e1f5-8793-42b0-8f18-628d7f6fe83a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[autogen.oai.client: 10-28 15:39:03] {129} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[autogen.oai.client: 10-28 15:39:03] {129} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        }
      ],
      "source": [
        "cathy = ConversableAgent(\n",
        "    name=\"cathy\",\n",
        "    system_message=\n",
        "    \"Your name is Cathy and you are a stand-up comedian.\",\n",
        "    llm_config=llm_config,\n",
        "    human_input_mode=\"NEVER\",\n",
        ")\n",
        "\n",
        "joe = ConversableAgent(\n",
        "    name=\"joe\",\n",
        "    system_message=\n",
        "    \"Your name is Joe and you are a stand-up comedian. \"\n",
        "    \"Start the next joke from the punchline of the previous joke.\",\n",
        "    llm_config=llm_config,\n",
        "    human_input_mode=\"NEVER\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43f71a61",
      "metadata": {
        "id": "43f71a61"
      },
      "source": [
        "**Note**: You might get a slightly different response (set of jokes) than what is shown in the video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "46a1c6f6-687e-40de-8819-374201cfed9f",
      "metadata": {
        "height": 98,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46a1c6f6-687e-40de-8819-374201cfed9f",
        "outputId": "6a8dcca9-1c3a-46fc-f395-d2b401c1a659"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "joe (to cathy):\n",
            "\n",
            "I'm Joe. Cathy, let's keep the jokes rolling.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "cathy (to joe):\n",
            "\n",
            "Hey Joe, great to meet you! Glad you're up for some laughs. So, I recently tried to make a belt out of watches, but it was a waist of time. Those things are hard to keep on schedule!\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "joe (to cathy):\n",
            "\n",
            "Haha, love that one! It's like trying to organize cats in a ballet class, right?\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "cathy (to joe):\n",
            "\n",
            "Exactly, Joe! It's all fun and games until the cats start improvising their own wild dance moves. It's like a furry, chaotic performance art piece!\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "chat_result = joe.initiate_chat(\n",
        "    recipient=cathy,\n",
        "    message=\"I'm Joe. Cathy, let's keep the jokes rolling.\",\n",
        "    max_turns=2,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78edc810",
      "metadata": {
        "id": "78edc810"
      },
      "source": [
        "## Print some results\n",
        "\n",
        "You can print out:\n",
        "\n",
        "1. Chat history\n",
        "2. Cost\n",
        "3. Summary of the conversation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "1169ea24-eadd-4909-8d56-9b7ec5677c66",
      "metadata": {
        "height": 64,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1169ea24-eadd-4909-8d56-9b7ec5677c66",
        "outputId": "6e941cea-58fd-4a7f-e07d-7bb892fe8ab7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'content': \"I'm Joe. Cathy, let's keep the jokes rolling.\",\n",
            "  'role': 'assistant'},\n",
            " {'content': \"Hey Joe, great to meet you! Glad you're up for some laughs. So, \"\n",
            "             'I recently tried to make a belt out of watches, but it was a '\n",
            "             'waist of time. Those things are hard to keep on schedule!',\n",
            "  'role': 'user'},\n",
            " {'content': \"Haha, love that one! It's like trying to organize cats in a \"\n",
            "             'ballet class, right?',\n",
            "  'role': 'assistant'},\n",
            " {'content': \"Exactly, Joe! It's all fun and games until the cats start \"\n",
            "             \"improvising their own wild dance moves. It's like a furry, \"\n",
            "             'chaotic performance art piece!',\n",
            "  'role': 'user'}]\n"
          ]
        }
      ],
      "source": [
        "import pprint\n",
        "\n",
        "pprint.pprint(chat_result.chat_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "550267b6-3652-40dc-9997-c5401f6d4c47",
      "metadata": {
        "height": 30,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "550267b6-3652-40dc-9997-c5401f6d4c47",
        "outputId": "962fe214-064f-4517-c405-9f324bef9551"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'usage_excluding_cached_inference': {'gpt-3.5-turbo-0125': {'completion_tokens': 100,\n",
            "                                                             'cost': 0.000273,\n",
            "                                                             'prompt_tokens': 246,\n",
            "                                                             'total_tokens': 346},\n",
            "                                      'total_cost': 0.000273},\n",
            " 'usage_including_cached_inference': {'gpt-3.5-turbo-0125': {'completion_tokens': 100,\n",
            "                                                             'cost': 0.000273,\n",
            "                                                             'prompt_tokens': 246,\n",
            "                                                             'total_tokens': 346},\n",
            "                                      'total_cost': 0.000273}}\n"
          ]
        }
      ],
      "source": [
        "pprint.pprint(chat_result.cost)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "dfcf468e-d217-4731-8cb4-3485377230f1",
      "metadata": {
        "height": 30,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfcf468e-d217-4731-8cb4-3485377230f1",
        "outputId": "33fc2b23-4c2d-4f63-cb88-fae2cc927d12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(\"Exactly, Joe! It's all fun and games until the cats start improvising their \"\n",
            " \"own wild dance moves. It's like a furry, chaotic performance art piece!\")\n"
          ]
        }
      ],
      "source": [
        "pprint.pprint(chat_result.summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba8c6cf8",
      "metadata": {
        "id": "ba8c6cf8"
      },
      "source": [
        "## Get a better summary of the conversation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "c1a8fef1-8030-4652-a2d2-1648834f62c2",
      "metadata": {
        "height": 132,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1a8fef1-8030-4652-a2d2-1648834f62c2",
        "outputId": "80a5508f-2c58-4f59-92b9-7ac328d08477"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "joe (to cathy):\n",
            "\n",
            "I'm Joe. Cathy, let's keep the jokes rolling.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "cathy (to joe):\n",
            "\n",
            "Hey Joe, great to meet you! Glad you're up for some laughs. So, I recently tried to make a belt out of watches, but it was a waist of time. Those things are hard to keep on schedule!\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "joe (to cathy):\n",
            "\n",
            "Haha, love that one! It's like trying to organize cats in a ballet class, right?\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "cathy (to joe):\n",
            "\n",
            "Exactly, Joe! It's all fun and games until the cats start improvising their own wild dance moves. It's like a furry, chaotic performance art piece!\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "chat_result = joe.initiate_chat(\n",
        "    cathy,\n",
        "    message=\"I'm Joe. Cathy, let's keep the jokes rolling.\",\n",
        "    max_turns=2,\n",
        "    summary_method=\"reflection_with_llm\",\n",
        "    summary_prompt=\"Summarize the conversation\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "b042de62-bc49-49ee-99f2-4f972e23670b",
      "metadata": {
        "height": 30,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b042de62-bc49-49ee-99f2-4f972e23670b",
        "outputId": "84728d09-4fc4-4215-d01e-34e5fd5dc6a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Joe and Cathy enjoyed sharing jokes and trading humorous anecdotes. They '\n",
            " 'compared the challenge of organizing watches on a belt to herding cats in a '\n",
            " 'ballet class, highlighting the chaos and unpredictability of both scenarios.')\n"
          ]
        }
      ],
      "source": [
        "pprint.pprint(chat_result.summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "300525bd",
      "metadata": {
        "id": "300525bd"
      },
      "source": [
        "## Chat Termination\n",
        "\n",
        "Chat can be terminated using a termination conditions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "044dfd61-7f1d-46d8-9e28-4b2601b43d70",
      "metadata": {
        "height": 351,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "044dfd61-7f1d-46d8-9e28-4b2601b43d70",
        "outputId": "221b50b4-7b5e-4a89-c4d6-ff9cac7b1370"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[autogen.oai.client: 10-28 15:40:18] {129} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[autogen.oai.client: 10-28 15:40:18] {129} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        }
      ],
      "source": [
        "cathy = ConversableAgent(\n",
        "    name=\"cathy\",\n",
        "    system_message=\n",
        "    \"Your name is Cathy and you are a stand-up comedian. \"\n",
        "    \"When you're ready to end the conversation, say 'I gotta go'.\",\n",
        "    llm_config=llm_config,\n",
        "    human_input_mode=\"NEVER\",\n",
        "    is_termination_msg=lambda msg: \"I gotta go\" in msg[\"content\"],\n",
        ")\n",
        "\n",
        "joe = ConversableAgent(\n",
        "    name=\"joe\",\n",
        "    system_message=\n",
        "    \"Your name is Joe and you are a stand-up comedian. \"\n",
        "    \"When you're ready to end the conversation, say 'I gotta go'.\",\n",
        "    llm_config=llm_config,\n",
        "    human_input_mode=\"NEVER\",\n",
        "    is_termination_msg=lambda msg: \"I gotta go\" in msg[\"content\"] or \"Goodbye\" in msg[\"content\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "bc49d959-1025-4709-8866-9d4035eaeae7",
      "metadata": {
        "height": 81,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc49d959-1025-4709-8866-9d4035eaeae7",
        "outputId": "a6bd6300-c18b-4be0-b2ca-739c76bc1474"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "joe (to cathy):\n",
            "\n",
            "I'm Joe. Cathy, let's keep the jokes rolling.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "cathy (to joe):\n",
            "\n",
            "Hey Joe! Glad to hear you're up for some laughs. Why did the scarecrow win an award? Because he was outstanding in his field!\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "joe (to cathy):\n",
            "\n",
            "Haha, I like that one, Cathy! How about this one: Why did the math book look sad? Because it had too many problems!\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "cathy (to joe):\n",
            "\n",
            "Haha, I love it! Sounds like that math book could use some tutoring. Here's one for you: Why don't scientists trust atoms? Because they make up everything!\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "joe (to cathy):\n",
            "\n",
            "Haha, that's a classic! Atoms can be so sneaky. Alright, Cathy, one more before I gotta go: Why did the golfer bring two pairs of pants? In case he got a hole in one!\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "chat_result = joe.initiate_chat(\n",
        "    recipient=cathy,\n",
        "    message=\"I'm Joe. Cathy, let's keep the jokes rolling.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "846eccbd-efd1-464b-9385-279c19b17c1d",
      "metadata": {
        "height": 45,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "846eccbd-efd1-464b-9385-279c19b17c1d",
        "outputId": "d50c8b7e-6ef3-4d6b-cda9-ad29f2d29b24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cathy (to joe):\n",
            "\n",
            "What's last joke we talked about?\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "joe (to cathy):\n",
            "\n",
            "The last joke we talked about was \"Why did the golfer bring two pairs of pants? In case he got a hole in one!\"\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "cathy (to joe):\n",
            "\n",
            "Haha, I gotta hand it to you, that one's a hole in one! Thanks for the good laughs, Joe! I gotta go.\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "cathy.send(message=\"What's last joke we talked about?\", recipient=joe)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}